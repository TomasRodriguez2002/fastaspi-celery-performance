# FastAPI + Celery + Redis + Docker - Tareas as√≠ncronas y procesamiento concurrente

Este proyecto es un experimento pr√°ctico para entender y demostrar c√≥mo manejar tareas intensivas de manera as√≠ncrona y distribuida usando **FastAPI, Celery, Redis y Docker**.

El objetivo es simular un escenario donde una API debe procesar m√∫ltiples tareas IO-bound (como llamadas HTTP que demoran varios segundos) y comparar c√≥mo se comporta de manera **secuencial** vs. **paralela usando Celery**.

## üöÄ Tecnolog√≠as utilizadas

- **FastAPI**: API web ligera y de alto rendimiento.
- **Celery**: Sistema de cola de tareas distribuido.
- **Redis**: Usado como broker y backend de Celery.
- **Docker / Docker Compose**: Para orquestar y aislar los servicios.

## ‚öôÔ∏è Arquitectura
```
+----------------+       +----------------+      +----------------+
|  FastAPI App   |  ---> |     Redis      | ---> | Celery Worker  |
| (fastapi_app)  |       |    (redis)     |      |(celery_worker) |
+----------------+       +----------------+      +----------------+
```

- **FastAPI App** expone endpoints REST para ejecutar las tareas.
- **Redis** act√∫a como intermediario, gestionando el estado y la cola de tareas.
- **Celery Worker** procesa las tareas en paralelo (con 5 workers de concurrencia).

## üìç Endpoints disponibles

- `GET /sequential`  
  Ejecuta 10 tareas IO-bound (llamadas a `https://httpbin.org/delay/3`) de manera **secuencial**.
  
- `GET /sequential_celery`  
  Ejecuta las mismas 10 tareas pero usando **Celery**, distribuy√©ndolas en paralelo.

- `GET /result/{task_id}`  
  Consulta el resultado de una tarea lanzada desde el endpoint `/sequential_celery`.

Accede a la documentaci√≥n interactiva de la API en:  
[http://localhost:8000/docs](http://localhost:8000/docs)

## üìä Resultados de la prueba

| M√©todo                | Tiempo de ejecuci√≥n |
|-----------------------|---------------------|
| Secuencial            |  39.54 segundos     |
| As√≠ncrono con Celery  |  8.58 segundos      |

### ‚úÖ Mejora obtenida

Reducci√≥n del **78.29%** en el tiempo total, logrando un **x4.6 de aceleraci√≥n** simplemente aplicando procesamiento distribuido con **Celery** y **Redis**.

## üö¢ C√≥mo correr el proyecto

Clonar el repositorio y ejecutar:

```bash
docker-compose up
```

La API estar√° disponible en:
http://localhost:8000/docs

## Pr√≥ximos pasos
- Integrar Flower para monitorizar en tiempo real el estado y rendimiento de los workers y las tareas.

- Explorar escalabilidad horizontal con m√∫ltiples workers.
